{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Yn3WxyeDPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac397474-ea7f-425b-b601-bc1895905b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Comparativo de Modelos (Teste) ===\n",
            "Random Forest        | R² = 0.5353 | RMSE = 68.20 | MAE = 32.69\n",
            "Árvore de Regressão  | R² = 0.1798 | RMSE = 90.60 | MAE = 38.87\n",
            "Regressão Linear     | R² = 0.1693 | RMSE = 91.17 | MAE = 52.55\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "# 1) Carregamento\n",
        "df = pd.read_csv(\"energydata_complete.csv\")\n",
        "\n",
        "# 2) Features / Target\n",
        "y = df[\"Appliances\"].copy()\n",
        "\n",
        "# Remover colunas não numéricas e a data (que não é um preditor)\n",
        "X = df.drop(columns=[\"Appliances\"], errors=\"ignore\")\n",
        "if \"date\" in X.columns:\n",
        "    X = X.drop(columns=[\"date\"], errors=\"ignore\")\n",
        "\n",
        "# 3) Split treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42\n",
        ")\n",
        "\n",
        "# 4) Modelos\n",
        "modelos = {\n",
        "    \"Regressão Linear\": LinearRegression(),  # regressão\n",
        "    \"Árvore de Regressão\": DecisionTreeRegressor(  # decision tree\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestRegressor(  # random forest\n",
        "        n_estimators=150,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# 5) Treino e avaliação\n",
        "def avalia(model, Xtr, Xte, ytr, yte):\n",
        "    model.fit(Xtr, ytr)\n",
        "    pred = model.predict(Xte)\n",
        "\n",
        "    r2 = r2_score(yte, pred)\n",
        "    rmse = float(np.sqrt(mean_squared_error(yte, pred)))\n",
        "    mae = float(mean_absolute_error(yte, pred))\n",
        "\n",
        "    return {\"R2\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
        "\n",
        "resultados = {}\n",
        "for nome, modelo in modelos.items():\n",
        "    resultados[nome] = avalia(modelo, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Ordena por RMSE (menor melhor)\n",
        "ordenados = sorted(resultados.items(), key=lambda kv: kv[1][\"RMSE\"])\n",
        "\n",
        "# 6) Exibição\n",
        "print(\"=== Comparativo de Modelos (Teste) ===\")\n",
        "for nome, mets in ordenados:\n",
        "    print(f\"{nome:20s} | R² = {mets['R2']:.4f} | RMSE = {mets['RMSE']:.2f} | MAE = {mets['MAE']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No nosso teste, o Random Forest se saiu muito melhor que os outros modelos. Ele conseguiu explicar mais da metade da variação no consumo de energia da casa e errou menos nas previsões. Isso acontece porque ele combina várias árvores e consegue captar relações mais complexas entre as variáveis.\n",
        "\n",
        "A Árvore de Regressão, sozinha, teve um desempenho bem mais fraco: acertou pouco da variação real e ainda errou bastante. Já a Regressão Linear foi a pior de todas, mostrando que o consumo de energia não segue uma relação simples e direta com as variáveis do ambiente.\n",
        "\n",
        "Em resumo: se a ideia é prever o uso de energia de forma confiável, o Random Forest é claramente a escolha mais adequada."
      ],
      "metadata": {
        "id": "gkbjPcNSpOt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# 1) Carregar dados\n",
        "df = pd.read_csv(\"smart_grid_stability_augmented.csv\")\n",
        "\n",
        "# 2) Features e alvo\n",
        "y_text = df[\"stabf\"].astype(str)\n",
        "# Mapeia: 0=stable, 1=unstable (nos interessa detectar instabilidade)\n",
        "y = y_text.map({\"stable\": 0, \"unstable\": 1}).astype(int)\n",
        "\n",
        "X = df.drop(columns=[\"stabf\"])\n",
        "# Garantir que só fiquem numéricas (caso haja algo residual)\n",
        "X = X.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "# 3) Split treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4) Modelos (simples)\n",
        "modelos = {\n",
        "    \"Árvore de Decisão\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN (k=7)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"knn\", KNeighborsClassifier(n_neighbors=7))\n",
        "    ]),\n",
        "    \"Regressão Logística\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"logreg\", LogisticRegression(max_iter=1000, random_state=42))\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# 5) Treinar e avaliar\n",
        "def avaliar(modelo, Xtr, Xte, ytr, yte):\n",
        "    modelo.fit(Xtr, ytr)\n",
        "    pred = modelo.predict(Xte)\n",
        "\n",
        "    acc = accuracy_score(yte, pred)\n",
        "    f1u = f1_score(yte, pred, pos_label=1)  # F1 para \"instável\"\n",
        "    cm = confusion_matrix(yte, pred, labels=[0,1])  # [[TN, FP],[FN, TP]]\n",
        "\n",
        "    return acc, f1u, cm\n",
        "\n",
        "resultados = {}\n",
        "for nome, mdl in modelos.items():\n",
        "    acc, f1u, cm = avaliar(mdl, X_train, X_test, y_train, y_test)\n",
        "    resultados[nome] = {\"Acurácia\": acc, \"F1_instável\": f1u, \"MatrizConfusão\": cm}\n",
        "\n",
        "# 6) Exibir resultados (limpo)\n",
        "print(\"=== Classificação: Estabilidade da Rede (0=stable, 1=unstable) ===\")\n",
        "for nome, mets in resultados.items():\n",
        "    cm = mets[\"MatrizConfusão\"]\n",
        "    print(f\"\\n{nome}\")\n",
        "    print(f\"Acurácia:     {mets['Acurácia']:.4f}\")\n",
        "    print(f\"F1 (instável): {mets['F1_instável']:.4f}\")\n",
        "    print(\"Matriz de Confusão [linhas=Real, colunas=Pred]:\")\n",
        "    print(pd.DataFrame(\n",
        "        cm,\n",
        "        index=[\"Real:0(stable)\", \"Real:1(unstable)\"],\n",
        "        columns=[\"Pred:0(stable)\", \"Pred:1(unstable)\"]\n",
        "    ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhS3mHV8p8TR",
        "outputId": "445f21b9-8143-4822-dff2-03c5ec01463d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Classificação: Estabilidade da Rede (0=stable, 1=unstable) ===\n",
            "\n",
            "Árvore de Decisão\n",
            "Acurácia:     1.0000\n",
            "F1 (instável): 1.0000\n",
            "Matriz de Confusão [linhas=Real, colunas=Pred]:\n",
            "                  Pred:0(stable)  Pred:1(unstable)\n",
            "Real:0(stable)              4344                 0\n",
            "Real:1(unstable)               0              7656\n",
            "\n",
            "KNN (k=7)\n",
            "Acurácia:     0.9557\n",
            "F1 (instável): 0.9657\n",
            "Matriz de Confusão [linhas=Real, colunas=Pred]:\n",
            "                  Pred:0(stable)  Pred:1(unstable)\n",
            "Real:0(stable)              4004               340\n",
            "Real:1(unstable)             191              7465\n",
            "\n",
            "Regressão Logística\n",
            "Acurácia:     0.9993\n",
            "F1 (instável): 0.9995\n",
            "Matriz de Confusão [linhas=Real, colunas=Pred]:\n",
            "                  Pred:0(stable)  Pred:1(unstable)\n",
            "Real:0(stable)              4338                 6\n",
            "Real:1(unstable)               2              7654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No teste que fizemos, a Árvore de Decisão acertou absolutamente tudo, mas esse tipo de modelo costuma “decorar” demais os dados e pode não se sair tão bem em situações novas. O KNN teve um bom desempenho, mas cometeu mais erros na hora de identificar instabilidades. Já a Regressão Logística ficou praticamente perfeita: simples, clara e quase sem falhas, o que mostra que ela é a opção mais confiável para detectar quando a rede está instável.\n",
        "\n",
        "Ou seja: se fosse para usar em uma aplicação real, o modelo mais seguro seria a Regressão Logística, porque une precisão com confiança para generalizar melhor."
      ],
      "metadata": {
        "id": "yGvK9eGqskOd"
      }
    }
  ]
}